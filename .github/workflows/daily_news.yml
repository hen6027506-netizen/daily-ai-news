name: Daily AI News Crawler

on:
  schedule:
    - cron: '0 0 * * *' # æ¯å¤© UTC 00:00 (å°ç£æ—©ä¸Š 08:00) åŸ·è¡Œ
  workflow_dispatch:    # å…è¨±æ‰‹å‹•åŸ·è¡Œ

jobs:
  run_crawler:
    runs-on: ubuntu-latest

    steps:
    - name: Check out code (ä¸‹è¼‰ç¨‹å¼ç¢¼)
      uses: actions/checkout@v4

    - name: Set up Python (å®‰è£ Python)
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies (å®‰è£å¥—ä»¶)
      run: |
        python -m pip install --upgrade pip
        # ğŸ‘‡ æ³¨æ„ï¼šé€™è£¡æ”¹æˆå®‰è£ google-generativeai
        pip install supabase google-generativeai requests beautifulsoup4 python-dotenv lxml

    - name: Run ETL Script (åŸ·è¡ŒæŠ“æ–°è)
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: python etl_worker.py
