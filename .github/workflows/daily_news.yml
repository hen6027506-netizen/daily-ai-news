name: Daily AI News Crawler

on:
  schedule:
    # è¨­å®šæ¯å¤© UTC æ™‚é–“ 00:00 åŸ·è¡Œ (å°ç£æ™‚é–“æ—©ä¸Š 8:00)
    - cron: '0 0 * * *'
  # å…è¨±æ‰‹å‹•æŒ‰æŒ‰éˆ•åŸ·è¡Œ (æ–¹ä¾¿æ¸¬è©¦)
  workflow_dispatch:

jobs:
  run_crawler:
    runs-on: ubuntu-latest

    steps:
    - name: Check out code (ä¸‹è¼‰ç¨‹å¼ç¢¼)
      uses: actions/checkout@v4

    - name: Set up Python (å®‰è£ Python)
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies (å®‰è£å¥—ä»¶)
      run: |
        python -m pip install --upgrade pip
        pip install supabase openai requests beautifulsoup4 python-dotenv

    - name: Run ETL Script (åŸ·è¡ŒæŠ“æ–°è)
      env:
        - name: Run ETL Script (åŸ·è¡ŒæŠ“æ–°è)
          env:
            SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
            SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
            # ğŸ‘‡ ä¿®æ”¹é€™ä¸€è¡Œï¼Œè®Šæ•¸åç¨±è¦è·Ÿ Python è£¡å¯«çš„ä¸€æ¨¡ä¸€æ¨£
            GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          run: python etl_worker.py